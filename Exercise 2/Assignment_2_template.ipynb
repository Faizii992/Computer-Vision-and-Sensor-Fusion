{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "import os \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here prepare the folder if does not exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3b82190714acbf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# you need the current working directory NB: works both windows and linux \n",
    "current_working_directory = os.getcwd()\n",
    "current_working_directory = os.path.dirname(current_working_directory)\n",
    "\n",
    "if not os.path.exists(f\"{current_working_directory}/Datasets\"):\n",
    "    os.makedirs(f\"{current_working_directory}/Datasets\")\n",
    "\n",
    "print(f\"[DATASET] PUT THE DATASET here: {current_working_directory}/Datasets\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "434e68dfeb1633f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the directory where I want to download the dataset\n",
    "path_of_dataset = os.path.join(*['..', current_working_directory, 'Datasets', 'Most_Stolen_Cars'])\n",
    "print(f\"[DIR] The directory of the current dataset is {path_of_dataset}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "defdff4a135ead77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data prep"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "447d59b3f7d8cc3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here let s do some functions that we can re-use also for other assignment\n",
    "def load_the_data_and_the_labels(data_set_path: str, target_size: tuple or None = None):\n",
    "    \"\"\"\n",
    "    This function help you to load the data dynamically \n",
    "    :param data_set_path: (str) put the path created in the previous cell (is the dataset path) \n",
    "    :param target_size: (tuple) the desired size of the images  \n",
    "    :return: \n",
    "        - array of images \n",
    "        - array with labels \n",
    "        - list of labels name (this is used for better visualization)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataset, labels, name_of_the_labels = list(), list(), list() \n",
    "        # let s loop here and we try to discover how many class we have \n",
    "        for class_number, class_name in enumerate(os.listdir(data_set_path)):\n",
    "            full_path_the_data = os.path.join(*[data_set_path, class_name])\n",
    "            print(f\"[WALK] I am walking into {full_path_the_data}\")\n",
    "            \n",
    "            # add the list to nam _list\n",
    "            name_of_the_labels.append(class_name)\n",
    "            \n",
    "            for single_image in os.listdir(f\"{full_path_the_data}\"):\n",
    "                full_path_to_image = os.path.join(*[full_path_the_data, single_image])\n",
    "                \n",
    "                # add the class number \n",
    "                labels.append(class_number)\n",
    "                \n",
    "                if target_size is None:\n",
    "                    # let s load the image \n",
    "                    image = tf.keras.utils.load_img(full_path_to_image)\n",
    "                else:\n",
    "                    image = tf.keras.utils.load_img(full_path_to_image, target_size=target_size)\n",
    "                \n",
    "                # transform PIL object in image                    \n",
    "                image = tf.keras.utils.img_to_array(image)\n",
    "                \n",
    "                # add the image to the ds list \n",
    "                dataset.append(image)\n",
    "                \n",
    "        return np.array(dataset, dtype='uint8'), np.array(labels, dtype='int'), name_of_the_labels\n",
    "    except Exception as ex:\n",
    "        print(f\"[EXCEPTION] load the data and the labels throws exceptions {ex}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3405eee338e0fd64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the data\n",
    "    a. Target size: (112, 112, 3)\n",
    "    b. if for some reason your pc crash saying Out of Memory reduce half the target size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f79f0130339f1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7973cebcbb20d03d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### normalize the data here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af74c30bde0b0295"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do it here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "528417cc2f944a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert the data to one hot encoding (use the sklearn function)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35a55f5ad876a548"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here we have to one hot encode the labes\n",
    "def make_the_one_hot_encoding(labels_to_transform):\n",
    "    try:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # this is a trick to figure the array as 2d array instead of list \n",
    "        temp = np.reshape(labels_to_transform, (-1, 1))\n",
    "        labels_to_transform = enc.fit_transform(temp).toarray()\n",
    "        print(f'[ONE HOT ENCODING] Labels are one-hot-encoded: {(labels_to_transform.sum(axis=1) - np.ones(labels_to_transform.shape[0])).sum() == 0}')\n",
    "        return labels_to_transform\n",
    "    except Exception as ex:\n",
    "        print(f\"[EXCEPTION] Make the one hot encoding throws exception {ex}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18fd4cb057df1206"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do it here "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab22d2252d6c9315"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# split the data in train set and test set \n",
    "    a. use 0.3 as split factor "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96757501c0af9934"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b275e038ef0426d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a CNN with the following characteristics\n",
    "        a. Input layer\n",
    "        b. As base model use VGG16:\n",
    "            i. Weights: imagenet\n",
    "            ii. Include_top: False\n",
    "            iii. Input_shape the target shape described in point 1. \n",
    "        c. Add a flatten layer \n",
    "        d. Add a Dense layer with 512 units and a dropout layer with 0.2 unit.\n",
    "        e. Add a Dense layer with 256 units and a dropout layer with 0.2 unit.\n",
    "        f. Add the final classifier with the correct number of units and the suitable activation.\n",
    "\n",
    "![alt text](assignment_2_tl.png \"CNN with tl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31ecd91adbc9d8b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do it here "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bf91a57e0496483"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set the layer block5_conv2, block5_conv3, block5_pool trainable \n",
    "    Important: you can make a function when you create a CNN within the option of make layers trainable or not is up to you!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1fd3db41f39251d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#do it here "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ce425805d88fab7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model \n",
    "    a. set the batch size 32 (if your PC go Out of memory lower this number half)\n",
    "    b. set epochs to 15"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c586846ebac571c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do it here "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43d93f75544c838a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### evaluate the model and record the accuracy score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "882f93173e1dead1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do it here "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "290f9e0b98d88831"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load again the CNN and set all the base model layers to not trainable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "222b3daf7b9d6d64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45dd94543d8d740b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Repeat the train and evaluation steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc8325ee9031aca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ed5fb7c9ce1ecb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What happen? Why?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cd66ea865699e0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make and visualize some predictions. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b412d65a40f3b4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# here "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5ad35f0ee782b0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
